# -*- coding: utf-8 -*-
"""0507_Object_DetectionAPI試してみた2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xpLCfqlT2NXxgZyeORwUsafYkQ3-x31e
"""

!wget http://images.cocodataset.org/zips/train2017.zip
!wget http://images.cocodataset.org/zips/val2017.zip
!wget http://images.cocodataset.org/zips/test2017.zip
!wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
!wget http://images.cocodataset.org/annotations/image_info_test2017.zip

!unzip "train2017.zip" 
!unzip "val2017.zip"
!unzip "test2017.zip"
!unzip "annotations_trainval2017.zip"
!unzip "image_info_test2017.zip"

!curl -OL https://github.com/google/protobuf/releases/download/v3.2.0/protoc-3.2.0-linux-x86_64.zip
!unzip protoc-3.2.0-linux-x86_64.zip -d protoc3
!sudo mv protoc3/bin/* /usr/local/bin/
!sudo mv protoc3/include/* /usr/local/include/
!rm -rf protoc3 protoc-3.2.0-linux-x86_64.zip

# Commented out IPython magic to ensure Python compatibility.
!git clone --depth 1 https://github.com/tensorflow/models
# %cd /content/models/research

!/usr/local/bin/protoc object_detection/protos/*.proto --python_out=.

!cp /content/models/research/object_detection/packages/tf2/setup.py .
!python -m pip install .

# インストール成否確認(Confirmation of successful installation)
!python /content/models/research/object_detection/builders/model_builder_tf2_test.py

!git clone https://github.com/Kazuhito00/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On.git

!unzip /content/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On-master.zip

!pip install object_detection

!pip install -q pycocotools
from pycocotools.coco import COCO

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle

import pylab
pylab.rcParams['figure.figsize'] = (8.0, 10.0)
import skimage.io as io

import os

import contextlib2
from object_detection.dataset_tools import tf_record_creation_util

from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import numpy as np
import IPython.display as display

import glob
import random
import shutil

from google.colab import drive
drive.mount('./gdrive')



!python /content/models/research/object_detection/dataset_tools/create_coco_tf_record.py --logtostderr \
      --train_image_dir='/content/train2017/' \
      --val_image_dir='/content/val2017/' \
      --test_image_dir='/content/test2017/'\
      --train_annotations_file='/content/annotations/instances_train2017.json' \
      --val_annotations_file='/content/annotations/instances_val2017.json' \
      --testdev_annotations_file='/content/annotations/image_info_test-dev2017.json' \
      --output_dir='/content/output_annotation' #新規でファイル作成した

!mv /content/output_annotation/coco_testdev.record-?????-of-00050 /content/output_annotation/test_tfrecord/

!mv /content/output_annotation/coco_train.record-?????-of-00100 /content/output_annotation/train_tfrecord/

!mv /content/output_annotation/coco_val.record-?????-of-00050 /content/output_annotation/val_tfrecord/



from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import numpy as np
import IPython.display as display

# TFRecordのパスを指定する
filenames = '/content/output_annotation/train_tfrecord/coco_train.record-00040-of-00100'
raw_dataset = tf.data.TFRecordDataset(filenames)

# 読み込んだ内容を別の形式に書き出す
# （.txtでも良い。jsonだとエディタ次第だが色ついて見やすくなるのでtxtよりオススメ）
tfr_data = 'tfr.json'

for raw_record in raw_dataset.take(1):
    example = tf.train.Example()
    example.ParseFromString(raw_record.numpy())
    print(example)

    # ファイルに書き出す。書き出さなくてもコンソールで見れるので必須ではない。
    with open(tfr_data, 'w') as f:
        print(example, file=f)

import numpy as np
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data





original_data_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/02_tfrecord'
train_data_dir = '/content/models/research/train_data'
val_data_dir = '/content/models/research/val_data'

# ディレクトリ作成(Create a directory)
import os
import shutil

shutil.rmtree(train_data_dir, ignore_errors=True)
shutil.rmtree(val_data_dir, ignore_errors=True)
os.mkdir(train_data_dir)
os.mkdir(val_data_dir)



!mkdir '/content/drive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On'



from google.colab import drive
drive.mount('./gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

!python /content/models/research/object_detection/model_main_tf2.py \
    --pipeline_config_path="/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/efficientdet_d0_coco17_tpu-32/pipeline.config" \
    --model_dir="/content/drive/MyDrive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/" #\
    #--num_train_steps=1000 \
    #--alsologtostderr \
    #--sample_1_of_n_eval_examples=1 \
    #--num_eval_steps=100

!python /content/models/research/object_detection/exporter_main_v2.py \
    --input_type=image_tensor \
    --pipeline_config_path="/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/efficientdet_d0_coco17_tpu-32/pipeline.config" \
    --trained_checkpoint_dir="/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/03_pretrained_model/efficientdet_d0_coco17_tpu-32/checkpoint/" \
    --output_directory="/content/drive/MyDrive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output/"



import tensorflow as tf

model_path = '/content/drive/My Drive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output/saved_model/'

DEFAULT_FUNCTION_KEY = 'serving_default'
loaded_model = tf.saved_model.load(model_path)
inference_func = loaded_model.signatures[DEFAULT_FUNCTION_KEY]

import tensorflow as tf

model_path = '/content/drive/My Drive/Tensorflow2-ObjectDetectionAPI/output/saved_model/'

DEFAULT_FUNCTION_KEY = 'serving_default'
loaded_model = tf.saved_model.load(model_path)
inference_func = loaded_model.signatures[DEFAULT_FUNCTION_KEY]

!mv /content/test2017/ /content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/



# 推論対象のテスト画像一覧(List of test images to be inferred)
import glob
import copy
import cv2
from google.colab.patches import cv2_imshow

test_data_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/'
testfile_list = sorted(glob.glob(test_data_dir + '/*.jpg'))

len(testfile_list)

image=testfile_list[0]

# 推論用関数(Function for inference)
def run_inference_single_image(image, inference_func):
    tensor = tf.convert_to_tensor(image)
    output = inference_func(tensor)

    output['num_detections'] = int(output['num_detections'][0])
    output['detection_classes'] = output['detection_classes'][0].numpy()
    output['detection_boxes'] = output['detection_boxes'][0].numpy()
    output['detection_scores'] = output['detection_scores'][0].numpy()
    return output

run_inference_single_image("/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/000000000001.jpg",inference_func)

tensor = tf.convert_to_tensor(image)
    output = inference_func(tensor)

    output['num_detections'] = int(output['num_detections'][0])
    output['detection_classes'] = output['detection_classes'][0].numpy()
    output['detection_boxes'] = output['detection_boxes'][0].numpy()
    output['detection_scores'] = output['detection_scores'][0].numpy()

tensor = tf.convert_to_tensor(image)

output = inference_func(tensor)



I = io.imread(image)

plt.imshow(I); plt.axis('off')



testfile_list[1000]



def load_image_into_numpy_array(path):
  """Load an image from file into a numpy array.

  Puts image into numpy array to feed into tensorflow graph.
  Note that by convention we put it into a numpy array with shape
  (height, width, channels), where channels=3 for RGB.

  Args:
    path: the file path to the image

  Returns:
    uint8 numpy array with shape (img_height, img_width, 3)
  """
  img_data = tf.io.gfile.GFile(path, 'rb').read()
  image = Image.open(BytesIO(img_data))
  (im_width, im_height) = image.size
  return np.array(image.getdata()).reshape(
      (im_height, im_width, 3)).astype(np.uint8)

def get_keypoint_tuples(eval_config):
  """Return a tuple list of keypoint edges from the eval config.
  
  Args:
    eval_config: an eval config containing the keypoint edges
  
  Returns:
    a list of edge tuples, each in the format (start, end)
  """
  tuple_list = []
  kp_list = eval_config.keypoint_edge
  for edge in kp_list:
    tuple_list.append((edge.start, edge.end))
  return tuple_list

pipeline_config = '/content/drive/MyDrive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output/pipeline.config'
model_dir = '/content/drive/MyDrive/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/output/checkpoint'

# Load pipeline config and build a detection model
configs = config_util.get_configs_from_pipeline_file(pipeline_config)
model_config = configs['model']
detection_model = model_builder.build(
      model_config=model_config, is_training=False)

# Restore checkpoint
ckpt = tf.compat.v2.train.Checkpoint(
      model=detection_model)
ckpt.restore(os.path.join(model_dir, 'ckpt-0')).expect_partial()

def get_model_detection_function(model):
  """Get a tf.function for detection."""

  @tf.function
  def detect_fn(image):
    """Detect objects in image."""

    image, shapes = model.preprocess(image)
    prediction_dict = model.predict(image, shapes)
    detections = model.postprocess(prediction_dict, shapes)

    return detections, prediction_dict, tf.reshape(shapes, [-1])

  return detect_fn

detect_fn = get_model_detection_function(detection_model)

from object_detection.utils import label_map_util
from object_detection.utils import config_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.builders import model_builder

# label_map_path = configs['eval_input_config'].label_map_path
label_map_path = '/content/models/research/object_detection/data/mscoco_label_map.pbtxt'
label_map = label_map_util.load_labelmap(label_map_path)
categories = label_map_util.convert_label_map_to_categories(
    label_map,
    max_num_classes=label_map_util.get_max_label_map_index(label_map),
    use_display_name=True)
category_index = label_map_util.create_category_index(categories)
label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)

testfile_list[1000]

image_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/'
image_path = os.path.join(image_dir, '000000014408.jpg')
image_np = load_image_into_numpy_array(image_path)

# Things to try:
# Flip horizontally
# image_np = np.fliplr(image_np).copy()

# Convert image to grayscale
# image_np = np.tile(
#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

input_tensor = tf.convert_to_tensor(
    np.expand_dims(image_np, 0), dtype=tf.float32)
detections, predictions_dict, shapes = detect_fn(input_tensor)

label_id_offset = 1
image_np_with_detections = image_np.copy()

# Use keypoints if available in detections
keypoints, keypoint_scores = None, None
if 'detection_keypoints' in detections:
  keypoints = detections['detection_keypoints'][0].numpy()
  keypoint_scores = detections['detection_keypoint_scores'][0].numpy()

viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'][0].numpy(),
      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
      detections['detection_scores'][0].numpy(),
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=.30,
      agnostic_mode=False,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=get_keypoint_tuples(configs['eval_config']))

plt.figure(figsize=(12,16))
plt.imshow(image_np_with_detections)
plt.show()

len(testfile_list)

testfile_list2=[testfile_list[22791],
testfile_list[5468],
testfile_list[36442],
testfile_list[12114],
testfile_list[5151],
testfile_list[27417],
testfile_list[39751],
testfile_list[27606],
testfile_list[27642],
testfile_list[9316]]

testfile_list2

image_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/'
image_path = os.path.join(image_dir, '000000014408.jpg')
image_np = load_image_into_numpy_array(image_path)

# Things to try:
# Flip horizontally
# image_np = np.fliplr(image_np).copy()

# Convert image to grayscale
# image_np = np.tile(
#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

input_tensor = tf.convert_to_tensor(
    np.expand_dims(image_np, 0), dtype=tf.float32)
detections, predictions_dict, shapes = detect_fn(input_tensor)

label_id_offset = 1
image_np_with_detections = image_np.copy()

# Use keypoints if available in detections
keypoints, keypoint_scores = None, None
if 'detection_keypoints' in detections:
  keypoints = detections['detection_keypoints'][0].numpy()
  keypoint_scores = detections['detection_keypoint_scores'][0].numpy()

viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'][0].numpy(),
      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
      detections['detection_scores'][0].numpy(),
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=.30,
      agnostic_mode=False,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=get_keypoint_tuples(configs['eval_config']))

plt.figure(figsize=(12,16))
plt.imshow(image_np_with_detections)
plt.show()



testfile_list[100]

import matplotlib
import matplotlib.pyplot as plt

import io
import scipy.misc
import numpy as np
from six import BytesIO
from PIL import Image, ImageDraw, ImageFont

import tensorflow as tf



def PrintImages(imagepath):
  image_np = load_image_into_numpy_array(image_path)

  input_tensor = tf.convert_to_tensor(
      np.expand_dims(image_np, 0), dtype=tf.float32)
  detections, predictions_dict, shapes = detect_fn(input_tensor)

  label_id_offset = 1
  image_np_with_detections = image_np.copy()

  # Use keypoints if available in detections
  keypoints, keypoint_scores = None, None

  if 'detection_keypoints' in detections:
    keypoints = detections['detection_keypoints'][0].numpy()
    keypoint_scores = detections['detection_keypoint_scores'][0].numpy()
  
  viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'][0].numpy(),
      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
      detections['detection_scores'][0].numpy(),
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=.30,
      agnostic_mode=False,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=get_keypoint_tuples(configs['eval_config']))
  plt.figure(figsize=(12,16))
  plt.imshow(image_np_with_detections)
  plt.show()

testfile_list2

image_dir = '/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/'
image_path = os.path.join(image_dir, '000000326696.jpg')
image_np = load_image_into_numpy_array(image_path)

# Things to try:
# Flip horizontally
# image_np = np.fliplr(image_np).copy()

# Convert image to grayscale
# image_np = np.tile(
#     np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)

input_tensor = tf.convert_to_tensor(
    np.expand_dims(image_np, 0), dtype=tf.float32)
detections, predictions_dict, shapes = detect_fn(input_tensor)

label_id_offset = 1
image_np_with_detections = image_np.copy()

# Use keypoints if available in detections
keypoints, keypoint_scores = None, None
if 'detection_keypoints' in detections:
  keypoints = detections['detection_keypoints'][0].numpy()
  keypoint_scores = detections['detection_keypoint_scores'][0].numpy()

viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'][0].numpy(),
      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
      detections['detection_scores'][0].numpy(),
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=.30,
      agnostic_mode=False,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=get_keypoint_tuples(configs['eval_config']))

plt.figure(figsize=(12,16))
plt.imshow(image_np_with_detections)
plt.show()

def PrintImage(image_dir,image_num):
  image_dir = image_dir
  image_path = os.path.join(image_dir, image_num)
  image_np = load_image_into_numpy_array(image_path)

  input_tensor = tf.convert_to_tensor(
      np.expand_dims(image_np, 0), dtype=tf.float32)
  detections, predictions_dict, shapes = detect_fn(input_tensor)

  label_id_offset = 1
  image_np_with_detections = image_np.copy()

  # Use keypoints if available in detections
  keypoints, keypoint_scores = None, None

  if 'detection_keypoints' in detections:
    keypoints = detections['detection_keypoints'][0].numpy()
    keypoint_scores = detections['detection_keypoint_scores'][0].numpy()
  
  viz_utils.visualize_boxes_and_labels_on_image_array(
      image_np_with_detections,
      detections['detection_boxes'][0].numpy(),
      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),
      detections['detection_scores'][0].numpy(),
      category_index,
      use_normalized_coordinates=True,
      max_boxes_to_draw=200,
      min_score_thresh=.30,
      agnostic_mode=False,
      keypoints=keypoints,
      keypoint_scores=keypoint_scores,
      keypoint_edges=get_keypoint_tuples(configs['eval_config']))
  plt.figure(figsize=(12,16))
  plt.imshow(image_np_with_detections)
  plt.show()

PrintImage('/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/','000000326696.jpg')

#testfile_list2

for i in range(len(testfile_list2)):
  PrintImage('/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/',testfile_list2[i])
  #PrintImages('/content/models/research/Tensorflow2-ObjectDetectionAPI-Colab-Hands-On/04_test_data/test2017/000000326696.jpg')



randomelist =[random.randint(0, 40665) for i in range(5)]
testfile_listA = [testfile_list[randomelist[i]] for i in range(len(randomelist))]

testfile_listA

for i in range(len(testfile_listA)):
  PrintImage(testfile_listA[i],'')

randomelist =[random.randint(0, 40665) for i in range(5)]
testfile_listA = [testfile_list[randomelist[i]] for i in range(len(randomelist))]
for i in range(len(testfile_listA)):
  PrintImage(testfile_listA[i],'')

randomelist =[random.randint(0, 40665) for i in range(5)]
testfile_listA = [testfile_list[randomelist[i]] for i in range(len(randomelist))]
for i in range(len(testfile_listA)):
  PrintImage(testfile_listA[i],'')



randomelist =[random.randint(0, 40665) for i in range(5)]
testfile_listA = [testfile_list[randomelist[i]] for i in range(len(randomelist))]
for i in range(len(testfile_listA)):
  PrintImage(testfile_listA[i],'')

randomelist =[random.randint(0, 40665) for i in range(5)]
testfile_listA = [testfile_list[randomelist[i]] for i in range(len(randomelist))]
for i in range(len(testfile_listA)):
  PrintImage(testfile_listA[i],'')
  print(testfile_listA[i])





